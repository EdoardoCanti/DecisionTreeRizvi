{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e22642b",
   "metadata": {},
   "source": [
    "##### Edoardo Canti\n",
    "# Role of demographics in online learning; A decision tree based approach\n",
    "\n",
    "\n",
    "### The aim of the following notebook is to reproduce the results obtained by Saman Rizvi, Bart Rienties and Shakeel Ahmed Khoja in section 4.1 of [their paper](https://www.sciencedirect.com/science/article/abs/pii/S0360131519300818?via%3Dihub).\n",
    "\n",
    "### While Rizvi, Rienties and Khoja used R programming language and its rpart( ) package for decision tree model implementation, in this work has been used Python programming language and [ScikitLearn](https://scikit-learn.org/stable/).\n",
    "\n",
    "### Dataset: [OULAD](https://analyse.kmi.open.ac.uk/open_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b148f",
   "metadata": {},
   "source": [
    "#### A very short review of the paper\n",
    "\n",
    "Rizvi et al. research was not the first work to prove the impact of student's individual characteristics on their learning outcomes, but has been one of the fewest that considered learning outcomes related to the course progression. \n",
    "\n",
    "By looking at the [OULAD dataset documentation](https://analyse.kmi.open.ac.uk/open_dataset#description) we can see that progression is represented by date_submitted attribute in studentAssessment table.\n",
    "\n",
    "With their work they proved not only that individual learner's characteristics impact on their learning outcomes but also that the impact of each individual characteristics changes over time! \n",
    "\n",
    "So now we could be interested in which individual characteristic impacts more on learning outcomes (on avarage, since we are considering these as time goes on).\n",
    "\n",
    "Now the only thing left to explain is which demographics characteristic Rizvi et al. used for their work?\n",
    "- gender\n",
    "- age band\n",
    "- region\n",
    "- [imd band](https://en.wikipedia.org/wiki/Multiple_deprivation_index)\n",
    "- disability\n",
    "- education level\n",
    "\n",
    "The development of models were divided in two phases. The aim of this project is to reproduce the development of models related to Phase 1.\n",
    "##### Phase 1\n",
    "Develop six predictive models:\n",
    "- S1,...,S5 for each **TMA (Teacher Marked Assignment)**, *Sx is related TMAx ( i=1,___,5 )* \n",
    "- S6 for the **final result**\n",
    "\n",
    "Consider that time progression is represented in TMAs by date attribute in assessment table; in their work (and consequently in this) progession in time is represented by model's name enumeration:\n",
    "*TMA1 is the first Teacher Marked Assignment, TMA5 in the last Teacher Marked Assignment*.\n",
    "\n",
    "**Phase 1 was applied over learners of course A (2013 module), who attempted all TMAs, final exam and never unregistered from the course (grand total of 289 learners)**.\n",
    "\n",
    "Learning outcomes are represented by three distinct values:\n",
    "\n",
    "| Label       | Related score |\n",
    "| ----------- | -----------   |\n",
    "| Fail        | < 55          |\n",
    "| Pass        | >= 55         |\n",
    "| Distinction | >= 85         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13d6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30778dda",
   "metadata": {},
   "source": [
    "## Dataset reading\n",
    "\n",
    "#### CHANGE THE FOLLOWING CELL INCLUDING THE PATHS OF THE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c253a807",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '<your_path_to_assessments.csv>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/by/s5tsgrlj5ws2sv5xjl7yqppr0000gn/T/ipykernel_10549/2568273318.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masmnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<your_path_to_assessments.csv>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<your_path_to_courses.csv>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstd_asmnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<your_path_to_studentAssessment.csv>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstd_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<your_path_to_studentInfo.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstd_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<your_path_to_studentRegistration.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '<your_path_to_assessments.csv>'"
     ]
    }
   ],
   "source": [
    "asmnt = pd.read_csv(\"<your_path_to_assessments.csv>\")\n",
    "crs = pd.read_csv(\"<your_path_to_courses.csv>\")\n",
    "std_asmnt = pd.read_csv(\"<your_path_to_studentAssessment.csv>\")\n",
    "std_info = pd.read_csv(\"<your_path_to_studentInfo.csv\")\n",
    "std_reg = pd.read_csv(\"<your_path_to_studentRegistration.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811cff1e",
   "metadata": {},
   "source": [
    "## Data filtering\n",
    "Recall on which student we need for Phase 1:\n",
    "- Registered to course A in 2013\n",
    "- Attempted all TMAs (five)\n",
    "- Attempted final exam\n",
    "- Never unregistered until the end of the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eefc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering only those assessments related to 2013 module presentation (actually of each Course)\n",
    "asmnt13 = asmnt[(asmnt['code_presentation']==\"2013J\")|(asmnt['code_presentation']==\"2013B\")]\n",
    "asmnt13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad1bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering those student that never unregistered from the course\n",
    "# Student who completed the course have date_unregistration attribute null in table studentRegistration\n",
    "never_unregistered = std_reg[std_reg['date_unregistration'].isnull()]\n",
    "never_unregistered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already had 2013 related assessments, now filtering those related to course A\n",
    "asmnt13_courseA = asmnt13[asmnt13['code_module']==\"AAA\"]\n",
    "asmnt13_courseA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f9651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering only students enrolled to course A\n",
    "std_reg = std_reg[std_reg['code_module']=='AAA']\n",
    "\n",
    "# From students enrolled to course A extract those enrolled in 2013\n",
    "std_reg = std_reg[(std_reg['code_presentation']==\"2013J\")|(asmnt['code_presentation']==\"2013B\")]\n",
    "\n",
    "# That never unregistered\n",
    "# Student who completed the course have date_unregistration attribute null in table studentRegistration\n",
    "std_reg = std_reg[std_reg['date_unregistration'].isnull()]\n",
    "\n",
    "std_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3080d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging students assessments with those assessments just extracted on id_assessmments\n",
    "# this means that now in this table every entry represent student assessments and also\n",
    "# gives infos about the assessment itself\n",
    "oxe = std_asmnt.merge(asmnt13_courseA, on=['id_assessment'])\n",
    "oxe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f875c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each student in oxe, searching for those who related to 5 assessments\n",
    "five_tmas_stud = []\n",
    "for ide in oxe['id_student']:\n",
    "    k = oxe[oxe['id_student']==ide]\n",
    "    if len(k) == 5:\n",
    "        five_tmas_stud.append(ide)\n",
    "\n",
    "print(len(five_tmas_stud))\n",
    "\n",
    "# Students enrolled in 2013 in course A, never unregistered, related to 5 assessments\n",
    "std_reg = std_reg.loc[std_reg['id_student'].isin(five_tmas_stud)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract the info (demographics of those students)\n",
    "# by looking at the resulting dataframe we note that there are also student related to other courses and \n",
    "# other presentations\n",
    "std_info = std_info.loc[std_info['id_student'].isin(std_reg['id_student'])]\n",
    "std_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd61d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clean again\n",
    "std_info = std_info.loc[(std_info['code_module'] == \"AAA\") & ((std_info['code_presentation'] == \"2013J\")|(std_info['code_presentation'] == \"2013B\"))]\n",
    "std_info\n",
    "\n",
    "# Did all attempted final exam?\n",
    "std_info['final_result'].isnull().values.any() #yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989327f3",
   "metadata": {},
   "source": [
    "So at this point std_info contains only students (learners):\n",
    "- in course A, \n",
    "- of year 2013, \n",
    "- which never unenrolled,\n",
    "- which attempted all five TMAs\n",
    "- that attempted final exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eda335",
   "metadata": {},
   "source": [
    "Now need to extract the correct assessments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73691cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only those assessments related to student in std_info\n",
    "std_asmnt = std_asmnt.loc[std_asmnt['id_student'].isin(std_info['id_student'])]\n",
    "std_asmnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df070c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only tmas from asmnt\n",
    "asmnt = asmnt.loc[(asmnt['assessment_type']==\"TMA\") & (asmnt['code_module']==\"AAA\") & \n",
    "                  ((asmnt['code_presentation']==\"2013J\") | (asmnt['code_presentation']==\"2013B\"))]\n",
    "asmnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee142dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking these out from std_asmnt\n",
    "std_asmnt = std_asmnt[std_asmnt['id_assessment'].isin(asmnt['id_assessment'])]\n",
    "std_asmnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff643a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing score values in DataFrame since Rizvi et al. worked on this labels rather then numbers\n",
    "\n",
    "for score in std_asmnt['score']:\n",
    "    if score < 55:\n",
    "        std_asmnt['score'] = std_asmnt['score'].replace([score],'Fail')\n",
    "    elif score >= 85:\n",
    "        std_asmnt['score'] = std_asmnt['score'].replace([score],'Distinction')\n",
    "    else:\n",
    "        std_asmnt['score'] = std_asmnt['score'].replace([score],'Pass')\n",
    "        \n",
    "std_asmnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630d0af5",
   "metadata": {},
   "source": [
    "## Getting all single TMAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tma1 = std_asmnt.loc[std_asmnt['id_assessment'] == 1752]\n",
    "tma2 = std_asmnt.loc[std_asmnt['id_assessment'] == 1753]\n",
    "tma3 = std_asmnt.loc[std_asmnt['id_assessment'] == 1754]\n",
    "tma4 = std_asmnt.loc[std_asmnt['id_assessment'] == 1755]\n",
    "tma5 = std_asmnt.loc[std_asmnt['id_assessment'] == 1756]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9277adb",
   "metadata": {},
   "source": [
    "## Functions used to deal with TMAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116895a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Takes a TMA ad attached to it the infos related to the student related.\n",
    "    I want to expand the sdt_asmnt (related to a certain tma) with the infos of the student that appears\n",
    "    in std_asmnt[id_student] '''\n",
    "def tma_merge(tma:pd.DataFrame) -> pd.DataFrame:\n",
    "    tma_stud = tma.merge(std_info, on=\"id_student\")\n",
    "    return tma_stud\n",
    "\n",
    "tma1_complete = tma_merge(tma1)\n",
    "tma2_complete = tma_merge(tma2)\n",
    "tma3_complete = tma_merge(tma3)\n",
    "tma4_complete = tma_merge(tma4)\n",
    "tma5_complete = tma_merge(tma5)\n",
    "\n",
    "tma1_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0505acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Used to encode data in TMAs (those obtained before)\n",
    "    We need to encode data because ScikitLearn DecisionTrees do not accept not numerical features. \n",
    "    Note: only features must be numerical, labels not.'''\n",
    "def tma_encoder(tma_complete:pd.DataFrame) -> pd.DataFrame:\n",
    "    encoded_tma = tma_complete\n",
    "    label_encoder = LabelEncoder()\n",
    "    tma_complete['gender'] = label_encoder.fit_transform(tma_complete['gender'])\n",
    "    label_encoder_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(label_encoder_name_mapping)\n",
    "    tma_complete['region'] = label_encoder.fit_transform(tma_complete['region'])\n",
    "    label_encoder_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(label_encoder_name_mapping)\n",
    "    tma_complete['highest_education'] = label_encoder.fit_transform(tma_complete['highest_education'])\n",
    "    label_encoder_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(label_encoder_name_mapping)\n",
    "    tma_complete['imd_band'] = label_encoder.fit_transform(tma_complete['imd_band'])\n",
    "    label_encoder_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(label_encoder_name_mapping)\n",
    "    tma_complete['age_band'] = label_encoder.fit_transform(tma_complete['age_band'])\n",
    "    label_encoder_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(label_encoder_name_mapping)\n",
    "    tma_complete['disability'] = label_encoder.fit_transform(tma_complete['disability'])\n",
    "    label_encoder_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(label_encoder_name_mapping)\n",
    "    return encoded_tma\n",
    "\n",
    "tma1_complete = tma_encoder(tma1_complete)\n",
    "\n",
    "tma2_complete = tma_encoder(tma2_complete)\n",
    "\n",
    "tma3_complete = tma_encoder(tma3_complete)\n",
    "\n",
    "tma4_complete = tma_encoder(tma4_complete)\n",
    "\n",
    "tma5_complete = tma_encoder(tma5_complete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for the final result\n",
    "final_complete = tma1_complete.drop(columns = [\"id_assessment\",\"date_submitted\",\"is_banked\",\"score\",\"num_of_prev_attempts\",\"studied_credits\"])\n",
    "final_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4eb8e0",
   "metadata": {},
   "source": [
    "## Class defined to respresent each predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20021432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictiveTMA:\n",
    "    \n",
    "    def __init__(self, tma, name,label):\n",
    "        self.X = tma[['gender','region','highest_education','imd_band','age_band','disability']]\n",
    "        self.y = tma[label] #label\n",
    "        self.name = name\n",
    "        \n",
    "    def splitter(self,n,rnd):\n",
    "        (self.X_train,self.X_test,self.y_train,self.y_test) = train_test_split(self.X,self.y,train_size=n,random_state=rnd)\n",
    "        report = \"X_train size: \"+str(len(self.X_train))+ \" ; y_train size: \"+str(len(self.y_train))\n",
    "        return report\n",
    "    \n",
    "    def get_X_train(self):\n",
    "        return self.X_train\n",
    "    \n",
    "    def get_y_train(self):\n",
    "        return self.y_train\n",
    "    \n",
    "    def get_X_test(self):\n",
    "        return self.X_test\n",
    "    \n",
    "    def get_y_test(self):\n",
    "        return self.y_test\n",
    "    \n",
    "    \n",
    "    #def get_tree(self,rnd) -> DecisionTreeClassifier:\n",
    "        #self.tree = DecisionTreeClassifier(random_state=rnd)\n",
    "        #self.tree.fit(self.X_train,self.y_train) \n",
    "        #return tree\n",
    "        \n",
    "    def get_tree(self,rnd):\n",
    "        param_grid = {'random_state':[rnd]}\n",
    "        clf = GridSearchCV(DecisionTreeClassifier(),param_grid,cv=5)\n",
    "        clf.fit(self.X, self.y)\n",
    "        clf = clf.best_estimator_\n",
    "        self.tree = clf\n",
    "        return self.tree\n",
    "    \n",
    "    def compute_predictions(self):\n",
    "        self.predictions = self.tree.predict(self.X_test)\n",
    "        return self.predictions\n",
    "    \n",
    "    def compute_accuracy(self):\n",
    "        self.accuracy = accuracy_score(self.y_test,self.predictions)\n",
    "        return self.accuracy\n",
    "    \n",
    "    def confusion_matrix(self):\n",
    "        plot_confusion_matrix(self.tree,self.X_test,self.y_test)\n",
    "        return confusion_matrix(self.y_test,self.predictions)\n",
    "    \n",
    "    def compute_precision(self):\n",
    "        self.precision = precision_score(self.y_test,self.predictions,average=None)\n",
    "        return self.precision\n",
    "    \n",
    "    def compute_recall(self):\n",
    "        self.recall = recall_score(self.y_test,self.predictions,average=None)\n",
    "        return self.recall\n",
    "    \n",
    "    def check_feature_importance(self):\n",
    "        self.feats = {} # a dict to hold feature_name: feature_importance\n",
    "        \n",
    "        for feature, importance in zip(self.X.columns, self.tree.feature_importances_):\n",
    "            self.feats[feature] = importance \n",
    "        \n",
    "        self.importance = pd.DataFrame.from_dict(self.feats, orient='index').rename(columns={0: 'feature importance'})\n",
    "        self.importance.sort_values(by='feature importance')\n",
    "        self.importance.plot(kind='bar', rot=45, title=str(self.name)+\" feature importance.\")\n",
    "        return self.feats\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc435981",
   "metadata": {},
   "source": [
    "## Class designed with responsabilites of running test and collecting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dceb87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    \n",
    "    def __init__(self,s1,s2,s3,s4,s5,s6):\n",
    "        self.models = []\n",
    "        self.models.append(s1)\n",
    "        self.models.append(s2)\n",
    "        self.models.append(s3)\n",
    "        self.models.append(s4)\n",
    "        self.models.append(s5)\n",
    "        self.models.append(s6)\n",
    "        self.predictions = []\n",
    "        self.accuracies = []\n",
    "        self.precisions = []\n",
    "        self.recalls = []\n",
    "        self.importances = []\n",
    "        \n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n",
    "    \n",
    "    def get_accuracies(self):\n",
    "        return self.accuracies\n",
    "    \n",
    "    def get_precisions(self):\n",
    "        return self.precisions\n",
    "    \n",
    "    def get_recalls(self):\n",
    "        return self.recalls\n",
    "    \n",
    "    def get_importances(self):\n",
    "        return self.importances\n",
    "        \n",
    "    def runner(self,rnd):\n",
    "        for model in self.models:\n",
    "            model.splitter(200, rnd)\n",
    "            decision_tree = model.get_tree(rnd)\n",
    "            predictions = model.compute_predictions()\n",
    "            self.predictions.append(predictions)\n",
    "            accuracy = model.compute_accuracy()\n",
    "            self.accuracies.append(accuracy)\n",
    "            precision = model.compute_precision()\n",
    "            self.precisions.append(precision)\n",
    "            recall = model.compute_recall()\n",
    "            self.recalls.append(recall)\n",
    "            feats = model.check_feature_importance()\n",
    "            self.importances.append(feats)\n",
    "            \n",
    "    def alternative_runner(self):\n",
    "        rnd = np.random.randint(100)\n",
    "        for model in self.models:\n",
    "            model.splitter(200, rnd)\n",
    "            decision_tree = model.get_tree(rnd)\n",
    "            predictions = model.compute_predictions()\n",
    "            self.predictions.append(predictions)\n",
    "            accuracy = model.compute_accuracy()\n",
    "            self.accuracies.append(accuracy)\n",
    "            precision = model.compute_precision()\n",
    "            self.precisions.append(precision)\n",
    "            recall = model.compute_recall()\n",
    "            self.recalls.append(recall)\n",
    "            feats = model.check_feature_importance()\n",
    "            self.importances.append(feats)\n",
    "        \n",
    "            \n",
    "    def single_test_summary(self, index):\n",
    "        print(\"Train Set:\\n\")\n",
    "        print(self.models[index].get_X_train())\n",
    "        print(self.models[index].get_y_train())\n",
    "        print(\"----\")\n",
    "        print(\"Test Set:\\n\")\n",
    "        print(self.models[index].get_X_test())\n",
    "        print(self.models[index].get_y_test())\n",
    "        print(\"----\")\n",
    "        print(\"Predictions: \"+str(self.predictions[index]))\n",
    "        print(\"----\")\n",
    "        print(\"Accuracy: \"+str(self.accuracies[index]))\n",
    "        print(\"----\")\n",
    "        print(\"Precision: \"+str(self.precisions[index]))\n",
    "        print(\"----\")\n",
    "        self.models[index].confusion_matrix()\n",
    "        print(\"----\")\n",
    "        print(\"Recall: \"+str(self.recalls[index]))\n",
    "        print(\"----\")\n",
    "        print(\"Feature importances: \"+str(self.importances[index]))\n",
    "        print(\"----\")\n",
    "        \n",
    "    \n",
    "    def handle_importances(self):\n",
    "        self.gender_imp = []\n",
    "        self.region_imp = []\n",
    "        self.highestedu_imp = []\n",
    "        self.imdband_imp = []\n",
    "        self.ageband_imp = []\n",
    "        self.disability_imp = []\n",
    "        \n",
    "        self.feat_imp = {}\n",
    "        \n",
    "        for dic in self.get_importances():\n",
    "            self.gender_imp.append(dic['gender'])\n",
    "            self.region_imp.append(dic['region'])\n",
    "            self.highestedu_imp.append(dic['highest_education'])\n",
    "            self.imdband_imp.append(dic['imd_band'])\n",
    "            self.ageband_imp.append(dic['age_band'])\n",
    "            self.disability_imp.append(dic['disability'])\n",
    "            \n",
    "        self.feat_imp['gender'] = self.gender_imp\n",
    "        self.feat_imp['region'] = self.region_imp\n",
    "        self.feat_imp['highest_education'] = self.highestedu_imp\n",
    "        self.feat_imp['imd_band'] = self.imdband_imp\n",
    "        self.feat_imp['age_band'] = self.ageband_imp\n",
    "        self.feat_imp['disability'] = self.disability_imp\n",
    "            \n",
    "    def plot_importances(self):\n",
    "        self.handle_importances()\n",
    "        sns.lineplot(data=self.feat_imp)\n",
    "        \n",
    "    def variable_importance_summary(self)->pd.DataFrame:\n",
    "        d = {}\n",
    "        d.update({'feature':[]})\n",
    "        d.update({'min':[]})\n",
    "        d.update({'max':[]})\n",
    "        d.update({'avg':[]})\n",
    "        for key in self.feat_imp.keys():\n",
    "            min_val = min(self.feat_imp[key])*100\n",
    "            max_val = max(self.feat_imp[key])*100\n",
    "            avg_val = np.mean(self.feat_imp[key])*100\n",
    "            d['feature'].append(key)\n",
    "            d['min'].append(min_val)\n",
    "            d['max'].append(max_val)\n",
    "            d['avg'].append(avg_val)\n",
    "        df = pd.DataFrame.from_dict(d)\n",
    "        df.sort_values(by=['avg'])\n",
    "        #df = df[['feature', 'min', 'max', 'avg']]\n",
    "        return df\n",
    "    \n",
    "    def show_alphas(self):\n",
    "        for model in self.models:\n",
    "            model.alpha()\n",
    "            \n",
    "    def execute_k_cross(self,k):\n",
    "        for model in self.models:\n",
    "            model.k_cross(k)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c9658",
   "metadata": {},
   "source": [
    "## Creating single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = PredictiveTMA(tma1_complete, \"TMA1\", \"score\")\n",
    "S1.splitter(200, 42)\n",
    "decision_tree = S1.get_tree(42)\n",
    "\n",
    "S2 = PredictiveTMA(tma2_complete, \"TMA2\", \"score\")\n",
    "S2.splitter(200, 42)\n",
    "decision_tree = S2.get_tree(42)\n",
    "\n",
    "S3 = PredictiveTMA(tma3_complete, \"TMA3\", \"score\")\n",
    "S3.splitter(200, 42)\n",
    "decision_tree = S3.get_tree(42)\n",
    "\n",
    "S4 = PredictiveTMA(tma4_complete, \"TMA4\", \"score\")\n",
    "S4.splitter(200, 42)\n",
    "decision_tree = S4.get_tree(42)\n",
    "\n",
    "S5 = PredictiveTMA(tma5_complete, \"TMA5\", \"score\")\n",
    "S5.splitter(200, 42)\n",
    "decision_tree = S5.get_tree(42)\n",
    "\n",
    "S6 = PredictiveTMA(final_complete, \"TMA6\", \"final_result\")\n",
    "S6.splitter(200, 42)\n",
    "decision_tree = S6.get_tree(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will also print a barplot showing feature(demographics) importance of each variable for each model\n",
    "test = Tester(S1,S2,S3,S4,S5,S6)\n",
    "test.runner(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb76ce",
   "metadata": {},
   "source": [
    "## Printing out summaries of each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02116d4",
   "metadata": {},
   "source": [
    "## S1 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854dd863",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.single_test_summary(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a65f2e",
   "metadata": {},
   "source": [
    "## S2 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225dabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.single_test_summary(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99edd4d7",
   "metadata": {},
   "source": [
    "## S3 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.single_test_summary(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8363e5",
   "metadata": {},
   "source": [
    "## S4 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.single_test_summary(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b4247",
   "metadata": {},
   "source": [
    "## S5 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.single_test_summary(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb50d52",
   "metadata": {},
   "source": [
    "## S6 (final result) summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a26f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.single_test_summary(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e4bd1",
   "metadata": {},
   "source": [
    "## Features importances over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.plot_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2372b3",
   "metadata": {},
   "source": [
    "## Showing results \n",
    "For each demographic characteristic the following DataFrame shows the minimum and the maximum value reached to its importance (scaled up to 100) and the average. By looking at the average value we can understand which impact more on result and which impact less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_im = test.variable_importance_summary()\n",
    "var_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e71d1",
   "metadata": {},
   "source": [
    "## Highlighting results\n",
    "\n",
    "As depicted in barplots and in the previous graph, we can see that the **impact of each variable on learning outcomes changes over time**. We are now interested in the importance on average. \n",
    "\n",
    "By our experiments it turns out that, in decresing order, **the most important variables are**:\n",
    "- region\n",
    "- imd band\n",
    "- highest education\n",
    "- age band\n",
    "- gender\n",
    "- disability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac954ee",
   "metadata": {},
   "source": [
    "## NOTES:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001180bf",
   "metadata": {},
   "source": [
    "### LabelEncoder:\n",
    "Is a function used to encode target values in numerical values in a range.\n",
    "\n",
    "If an attribute **X** has a not numerical domain **Dom(X)** with cardinality **N** a label encoding applied to **X** will transform **Dom(X)** to {0,...,N-1}.\n",
    "\n",
    "This has been done because ScikitLearn implementation of decision trees doesn't support not numerical values in X set. However it supports not numerical in y set.\n",
    "\n",
    "To apply this operation we also came accross OneHotEncoding(). Here is why we didn't used it:\n",
    "\n",
    "*For simplicity imagine now that imd_band domain contains only three values: Ireland (I), London(L), Wales(W)*.\n",
    "\n",
    "Consider we are trying to convert *imd_band* values into numerical using *OneHotEncoding*. \n",
    "What *OneHotEncoding* does is to create three distinct new *dummy variables* (and so attributes). *Each object* now will have these three new dummy variables indicating if the object itself has *that variable true or false (0,1)*. So if now we will try to *compute variable importance*, we will not have a single variable importance for the variable *imd_band* but instead we will compute the single importances of living in Ireland(I), London(L), Wales(S); this is not what we want.\n",
    "\n",
    "What happens using LabelEncoder: \n",
    "   - imagine Dom(imd_band) = {I,L,W}\n",
    "   - imagine encoding as I->0, L->1, W->2\n",
    "    \n",
    "| id_student  | imd_band      |\n",
    "| ----------- | -----------   |\n",
    "| id_a        | 0             |\n",
    "| id_b        | 2             |\n",
    "| id_c        | 1             |\n",
    "\n",
    "\n",
    "What happened using OneHotEncoding: \n",
    "   - imagine Dom(imd_band) = {I,L,W}\n",
    "   - imagine encoding as I->0, L->1, W->2\n",
    " \n",
    "    \n",
    "| id_student  | is_I          | is_L        | is_W        |\n",
    "| ----------- | -----------   | ---------   | ---------   |\n",
    "| id_a        | 1             | 0           | 0           |\n",
    "| id_b        | 0             | 0           | 1           |\n",
    "| id_c        | 0             | 1           | 0           |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6187c122",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "Looking at the PredictiveTMA class you will see two different *get_tree(self)* functions, one of which is commented. We decided to leave that one commented to emphisize what we are going to say.\n",
    "\n",
    "```\n",
    "def get_tree(self,rnd) -> DecisionTreeClassifier:\n",
    "    self.tree = DecisionTreeClassifier(random_state=rnd)\n",
    "    self.tree.fit(self.X_train,self.y_train) \n",
    "    return tree\n",
    "```\n",
    "With this snippet of code we are just creating and fitting a Decision Tree.\n",
    "\n",
    "When using this function to create a *Decision Tree* we just gave to the Tree an *uncertainity on how it will select the sample: random_state=rnd* if *rnd is an integer* it will be used as a *seed to generate random samples*. If we use a *fixed integer for rnd*, we will be sure that every time it will pick the same sammples; this is actually good because we are going to generate six distinct models!\n",
    "\n",
    "However if we decide that *random_state=None* what happens is that it will produce diffent instances. Buy running the function using *random_state=None*, we arrived to different result with respect to those obtained with a fixed integer random_state. \n",
    "What we noticed is that sometimes we obtained same results of Rizvi et al. (when region is the most important variable while other times imd_band was the most one). Maybe there was something we didn't consider in our approach.\n",
    "\n",
    "It turns out that rpart() package used by Rizvi et al. uses k-fold cross validation.\n",
    "This is why we used GridSearchCV and builded the Decision Trees using the best estimator (Rizvi et al. didn't specfied the k value of cross validation, we used 5 because is very common).\n",
    "\n",
    "```\n",
    "def get_tree(self,rnd):\n",
    "        param_grid = {'random_state':[rnd]}\n",
    "        clf = GridSearchCV(DecisionTreeClassifier(),param_grid,cv=5)\n",
    "        clf.fit(self.X, self.y)\n",
    "        clf = clf.best_estimator_\n",
    "        self.tree = clf\n",
    "        return self.tree\n",
    "```\n",
    "With this new *get_tree* function we now started to obtain the same result of Rizvi et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e5861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
